<div align="center">

<img src="https://github.com/user-attachments/assets/0370a117-cff9-43bd-8cd1-76d4d9cc64bd" alt="Respondo - Web scraping, text extraction & AI parsing for Python" width="100%">

<br>

[![PyPI version](https://img.shields.io/pypi/v/respondo?color=00d4aa&label=PyPI&style=flat-square)](https://pypi.org/project/respondo/)
[![Python](https://img.shields.io/badge/Python-3.9+-3776ab?logo=python&logoColor=white&style=flat-square)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-a855f7?style=flat-square)](https://opensource.org/licenses/MIT)
[![Downloads](https://img.shields.io/pypi/dm/respondo?color=fbbf24&style=flat-square)](https://pypi.org/project/respondo/)
[![Discord](https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&logoColor=white&style=flat-square)](https://discord.gg/n9cdFy7ngN)

**Zero dependencies** · **Type hints** · **10 AI providers** · **199 functions**

[Installation](#installation) · [Quick Start](#quick-start) · [Documentation](#documentation) · [AI Parsing](#ai-parsing)

</div>

---

## Installation

```bash
pip install respondo
```

---

## Quick Start

```python
from respondo import between, extract_emails, parse_ai, Response

# Extract text between delimiters
between("<title>Hello World</title>", "<title>", "</title>")
# => "Hello World"

# Find all emails in text
extract_emails("Contact us at hello@example.com or support@example.com")
# => ["hello@example.com", "support@example.com"]

# AI-powered extraction (10 providers supported)
parse_ai("Extract the price", "The item costs $29.99", provider="openai")
# => "$29.99"
```

---

## Documentation

### Text Extraction

```python
from respondo import between, betweens, before, after, split_first

# Extract between delimiters
between("Hello [World]!", "[", "]")           # => "World"
betweens("[a][b][c]", "[", "]")               # => ["a", "b", "c"]

# Before/after extraction
before("user@example.com", "@")               # => "user"
after("user@example.com", "@")                # => "example.com"

# Split utilities
split_first("a/b/c", "/")                     # => ("a", "b/c")
```

### String Utilities

```python
from respondo import to_snake_case, slugify, truncate, reverse, pad_left

to_snake_case("helloWorld")      # => "hello_world"
to_camel_case("hello_world")     # => "helloWorld"
slugify("Hello World!")          # => "hello-world"
truncate("hello world", 8)       # => "hello..."
reverse("hello")                 # => "olleh"
pad_left("42", 5, "0")           # => "00042"
```

### Safe Parsing

```python
from respondo import parse_int, parse_float, parse_bool

parse_int("42")           # => 42
parse_int("invalid", -1)  # => -1 (default)
parse_float("3.14")       # => 3.14
parse_bool("yes")         # => True
```

### Encoding & Hashing

```python
from respondo import sha256, md5, b64_encode, hex_encode, hmac_sha256

sha256("hello")                    # => "2cf24dba5fb0a30e..."
md5("hello")                       # => "5d41402abc4b2a76..."
b64_encode("hello")                # => "aGVsbG8="
hex_encode("hello")                # => "68656c6c6f"
hmac_sha256("secret", "message")   # => "..."
```

### UUID & Random

```python
from respondo import uuid4, random_hex, random_string, random_urlsafe

uuid4()                # => "550e8400-e29b-41d4-..."
random_hex(16)         # => "a1b2c3d4e5f67890"
random_string(10)      # => "xK9mP2nQ4r"
random_urlsafe(16)     # => "Yx2kM9pN_3qR-w5z"
```

### Timestamps

```python
from respondo import timestamp, from_timestamp, to_timestamp

timestamp()                           # => 1705320000
from_timestamp(1705320000)            # => "2024-01-15T12:00:00Z"
to_timestamp("2024-01-15T12:00:00Z")  # => 1705320000
```

---

### HTML Parsing

```python
from respondo import get_text, extract_links, extract_meta, extract_images, html_to_markdown

html = """
<html>
  <head>
    <title>My Page</title>
    <meta name="description" content="A sample page">
    <meta property="og:image" content="https://example.com/image.jpg">
  </head>
  <body>
    <h1>Welcome</h1>
    <p>Visit our <a href="/about">about page</a></p>
    <img src="/logo.png" alt="Logo">
  </body>
</html>
"""

# Extract visible text
get_text(html)  # => "My Page Welcome Visit our about page"

# Extract all links
extract_links(html, base="https://example.com")
# => ["https://example.com/about", "https://example.com/logo.png"]

# Extract meta tags (title, description, og:*, twitter:*)
extract_meta(html)
# => {"title": "My Page", "description": "A sample page", "og:image": "https://example.com/image.jpg"}

# Extract images with attributes
extract_images(html, base="https://example.com")
# => [{"src": "https://example.com/logo.png", "alt": "Logo", ...}]

# Convert HTML to Markdown
html_to_markdown("<h1>Title</h1><p>Hello <strong>world</strong></p>")
# => "# Title\n\nHello **world**"
```

### Forms & Tables

```python
from respondo import extract_forms, extract_tables

# Extract forms with all fields
html = '<form action="/login"><input name="user"><input name="pass" type="password"></form>'
extract_forms(html, base="https://example.com")
# => [{"action": "https://example.com/login", "method": "get", "fields": {"user": "", "pass": ""}}]

# Extract tables as structured data
html = "<table><tr><th>Name</th><th>Age</th></tr><tr><td>Alice</td><td>30</td></tr></table>"
extract_tables(html)
# => [{"headers": ["Name", "Age"], "rows": [{"Name": "Alice", "Age": "30"}]}]
```

---

### JSON Utilities

```python
from respondo import find_first_json, find_all_json, json_get

# Find JSON embedded in text
find_first_json('callback({"user": "alice", "id": 42})')
# => {"user": "alice", "id": 42}

# Safe nested access (never throws)
data = {"user": {"profile": {"name": "Alice"}}}
json_get(data, "user", "profile", "name")     # => "Alice"
json_get(data, "user", "missing", "key")      # => None

# Works with arrays too
json_get([{"id": 1}, {"id": 2}], 0, "id")     # => 1
```

---

### Response Handling

```python
from respondo import Response

resp = Response(
    status=200,
    headers={"Content-Type": "application/json"},
    body=b'{"success": true}'
)

# Status checks
resp.is_success()        # => True (200-299)
resp.is_redirect()       # => False (300-399)
resp.is_client_error()   # => False (400-499)

# Body access
resp.text                # => '{"success": true}'
resp.json()              # => {"success": True}

# Save to file
resp.save("output.html")         # Save raw body
resp.save_text("output.txt")     # Save decoded text
resp.save_json("output.json")    # Save formatted JSON
resp.save_zip("output.zip")      # Save as compressed zip

# Headers (case-insensitive)
resp.header("content-type")       # => "application/json"
resp.content_type()               # => ("application/json", "")
```

---

### Social Media Extraction

```python
from respondo import (
    extract_discord_invites, extract_telegram_links, extract_twitter_links,
    extract_youtube_links, extract_instagram_links, extract_tiktok_links,
    extract_reddit_links, extract_social_links
)

# Extract individual platforms
extract_discord_invites("Join discord.gg/abc123")     # => ["abc123"]
extract_telegram_links("Follow t.me/channel")         # => ["channel"]
extract_twitter_links("Check twitter.com/elonmusk")   # => ["https://twitter.com/elonmusk"]
extract_youtube_links("Watch https://youtu.be/xyz")   # => ["https://youtu.be/xyz"]

# Extract all social links at once
extract_social_links("discord.gg/test t.me/channel twitter.com/user")
# => {"discord": ["test"], "telegram": ["channel"], "twitter": ["https://twitter.com/user"], ...}
```

### Crypto/Web3 Extraction

```python
from respondo import (
    extract_eth_addresses, extract_btc_addresses, extract_sol_addresses,
    extract_ens_names, extract_crypto_addresses
)

# Ethereum
extract_eth_addresses("Send to 0x742d35Cc6634C0532925a3b844Bc9e7595f1dE2B")
# => ["0x742d35Cc6634C0532925a3b844Bc9e7595f1dE2B"]

# Bitcoin (legacy and SegWit)
extract_btc_addresses("BTC: 1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2")
# => ["1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2"]

# ENS names
extract_ens_names("Contact vitalik.eth")  # => ["vitalik.eth"]

# All crypto at once
extract_crypto_addresses(text)  # => {"eth": [...], "btc": [...], "sol": [...], "ens": [...]}
```

### Security Token Extraction

```python
from respondo import extract_api_keys, extract_jwts, decode_jwt, extract_bearer_tokens

# Detect exposed API keys (OpenAI, AWS, Stripe, GitHub, Google, etc.)
extract_api_keys("OPENAI_API_KEY=sk-abc123...")
# => [{"type": "openai", "key": "sk-abc123..."}]

# Extract and decode JWTs
tokens = extract_jwts("token=eyJhbGciOiJIUzI1NiIs...")
decode_jwt(tokens[0])  # => {"header": {"alg": "HS256"}, "payload": {"sub": "123"}}

# Bearer tokens
extract_bearer_tokens("Authorization: Bearer abc123")  # => ["abc123"]
```

---

### Captcha Extraction & Detection

```python
from respondo import (
    # Extraction
    extract_recaptcha_sitekey, extract_turnstile_sitekey, extract_hcaptcha_sitekey,
    extract_captcha_params,
    # Detection
    contains_recaptcha, contains_turnstile, contains_hcaptcha
)

html = '<div class="g-recaptcha" data-sitekey="6Lc..."></div>'

# Extract site keys for captcha solving services
extract_recaptcha_sitekey(html)   # => ["6Lc..."]
extract_turnstile_sitekey(html)   # => ["0x4AAA..."]
extract_hcaptcha_sitekey(html)    # => ["uuid-format-key"]

# Check what captcha is present
contains_recaptcha(html)          # => True
contains_turnstile(html)          # => False
contains_hcaptcha(html)           # => False

# Get all captcha params at once
extract_captcha_params(html)
# => {"recaptcha": [...], "turnstile": [...], "hcaptcha": [...]}
```

### Bot Protection Detection

```python
from respondo import detect_protection_system, detect_all_protection_systems

# Detect primary protection
detect_protection_system(html)  # => "cloudflare" / "datadome" / "akamai" / etc.

# Detect all protection systems
detect_all_protection_systems(html)
# => ["cloudflare", "recaptcha"]
```

### Network/Identifier Extraction

```python
from respondo import (
    extract_ipv4, extract_ipv6, extract_ips, extract_domains,
    extract_uuids, extract_mac_addresses
)

extract_ipv4("Server: 192.168.1.1")                  # => ["192.168.1.1"]
extract_domains("Visit example.com or api.test.org") # => ["example.com", "api.test.org"]
extract_uuids("ID: 550e8400-e29b-41d4-a716-...")     # => ["550e8400-..."]
extract_mac_addresses("MAC: 00:1A:2B:3C:4D:5E")      # => ["00:1A:2B:3C:4D:5E"]
```

### E-commerce Extraction

```python
from respondo import extract_prices, extract_skus

extract_prices("Price: $19.99 and EUR 29.99")
# => [{"raw": "$19.99", "value": 19.99, "currency": "USD"},
#     {"raw": "EUR 29.99", "value": 29.99, "currency": "EUR"}]

extract_skus("SKU: ABC-12345")  # => ["ABC-12345"]
```

---

## AI Parsing

Parse text using LLM APIs. **10 providers supported** with structured output.

```python
from respondo import parse_ai, parse_ai_json, list_providers

# See all providers
list_providers()
# => {"openai": "gpt-4o-mini", "anthropic": "claude-3-5-haiku-latest", ...}

# Basic extraction
parse_ai("Extract all prices", "$29.99 and $49.99", provider="openai")
# => "$29.99, $49.99"

# Custom model
parse_ai("Summarize", text, provider="anthropic", model="claude-3-5-sonnet-latest")

# JSON response
parse_ai_json("Extract name and age", "John is 30", provider="openai")
# => {"name": "John", "age": 30}

# Structured output with schema (enforced by provider)
schema = {
    "type": "object",
    "properties": {
        "name": {"type": "string"},
        "age": {"type": "integer"}
    },
    "required": ["name", "age"],
    "additionalProperties": False
}
parse_ai_json("Extract person", text, provider="openai", schema=schema)
```

### Supported Providers

| Provider | Environment Variable | Default Model |
|:---------|:--------------------|:--------------|
| `openai` | `OPENAI_API_KEY` | `gpt-4o-mini` |
| `anthropic` | `ANTHROPIC_API_KEY` | `claude-3-5-haiku-latest` |
| `gemini` | `GEMINI_API_KEY` | `gemini-2.0-flash` |
| `grok` | `GROK_API_KEY` | `grok-2-latest` |
| `mistral` | `MISTRAL_API_KEY` | `mistral-small-latest` |
| `groq` | `GROQ_API_KEY` | `llama-3.3-70b-versatile` |
| `cohere` | `COHERE_API_KEY` | `command-r` |
| `together` | `TOGETHER_API_KEY` | `Llama-3.3-70B-Instruct-Turbo` |
| `deepseek` | `DEEPSEEK_API_KEY` | `deepseek-chat` |
| `perplexity` | `PERPLEXITY_API_KEY` | `sonar` |

---

## All Functions

<details>
<summary><b>Text Parsing (50+)</b></summary>

- `between`, `betweens`, `between_last`, `between_n`, `between_nested`
- `before`, `after`, `before_last`, `after_last`
- `split_first`, `split_last`
- `line_containing`, `lines_containing`, `lines_between`
- `around`, `attr`, `attrs`
- `take`, `take_last`, `skip`, `skip_last`, `truncate`
- `to_snake_case`, `to_camel_case`, `to_pascal_case`, `to_kebab_case`, `to_title_case`
- `remove`, `replace_first`, `replace_last`, `pad_left`, `pad_right`, `reverse`
- `count_occurrences`, `contains_all`, `contains_any`, `starts_with_any`, `ends_with_any`
- `is_empty`, `is_numeric`
- `words`, `word_count`, `sentences`, `first_word`, `last_word`, `nth_word`
- `parse_int`, `parse_float`, `parse_bool`
- `slugify`, `to_filename`
- `common_prefix`, `common_suffix`, `similarity`
- `normalize_space`, `strip_tags`, `unescape_html`, `clean_text`
- `regex_first`, `regex_all`

</details>

<details>
<summary><b>Encoding & Crypto (40+)</b></summary>

- `b64_encode`, `b64_decode`, `url_encode`, `url_decode`
- `hex_encode`, `hex_decode`, `b32_encode`, `b32_decode`
- `a85_encode`, `a85_decode`, `b85_encode`, `b85_decode`
- `rot13`, `punycode_encode`, `punycode_decode`
- `quote`, `unquote`
- `md5`, `sha1`, `sha256`, `sha512`, `sha224`, `sha384`, `sha3_256`, `sha3_512`
- `blake2b`, `blake2s`, `crc32`, `adler32`
- `hmac_sha256`, `hmac_sha512`, `hash_data`
- `hash_password`, `verify_password`
- `uuid4`, `uuid5`, `uuid1`
- `random_bytes`, `random_hex`, `random_string`, `random_urlsafe`
- `timestamp`, `timestamp_ms`, `from_timestamp`, `to_timestamp`

</details>

<details>
<summary><b>Extraction (50+)</b></summary>

- `extract_emails`, `extract_urls`, `extract_numbers`
- `extract_discord_invites`, `extract_telegram_links`, `extract_twitter_links`
- `extract_youtube_links`, `extract_instagram_links`, `extract_tiktok_links`
- `extract_reddit_links`, `extract_social_links`
- `extract_eth_addresses`, `extract_btc_addresses`, `extract_sol_addresses`
- `extract_ens_names`, `extract_crypto_addresses`
- `extract_api_keys`, `extract_jwts`, `decode_jwt`, `extract_bearer_tokens`
- `extract_phone_numbers`, `extract_dates`
- `extract_ipv4`, `extract_ipv6`, `extract_ips`, `extract_domains`
- `extract_uuids`, `extract_mac_addresses`
- `extract_api_endpoints`, `extract_graphql_endpoints`, `extract_websocket_urls`
- `extract_video_urls`, `extract_audio_urls`, `extract_stream_urls`
- `extract_prices`, `extract_skus`
- `extract_canonical_url`, `extract_og_tags`, `extract_twitter_cards`
- `extract_schema_org`, `extract_structured_data`

</details>

<details>
<summary><b>HTML & JSON (15+)</b></summary>

- `strip_scripts_styles`, `get_text`, `extract_links`, `extract_forms`
- `extract_tables`, `extract_meta`, `extract_images`, `html_to_markdown`
- `json_in_html`, `find_first_json`, `find_all_json`, `json_get`

</details>

<details>
<summary><b>Bot Protection (20+)</b></summary>

- `extract_recaptcha_sitekey`, `extract_turnstile_sitekey`, `extract_hcaptcha_sitekey`
- `contains_recaptcha`, `contains_turnstile`, `contains_hcaptcha`
- `detect_protection_system`, `detect_all_protection_systems`
- `extract_akamai_sensor_script`, `extract_datadome_object`
- `extract_incapsula_challenge_marker`, `extract_kasada_endpoints`

</details>

<details>
<summary><b>Validation (5+)</b></summary>

- `is_valid_email`, `is_valid_url`, `is_valid_json`
- `is_empty`, `is_numeric`

</details>

---

## Features Overview

<div align="center">
<img src="https://github.com/user-attachments/assets/f5635db0-4ede-4736-9014-2a4be814981b" alt="Features" width="100%">
</div>

---

## Error Handling

All functions return empty values instead of raising exceptions - ideal for scraping workflows where missing data is expected.

| Return Type | On Failure |
|:------------|:-----------|
| `str` | `""` |
| `list` | `[]` |
| `dict` | `{}` |
| `Any` (JSON) | `None` |

```python
between("no match", "<", ">")      # => ""
find_first_json("not json")        # => None
is_valid_email("invalid")          # => False
extract_emails("no emails here")   # => []
parse_ai("prompt", "text")         # => "" (if no API key)
```

---

<div align="center">

**MIT License** - Made for web scrapers

</div>
